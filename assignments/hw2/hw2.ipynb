{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHdhDx3SfbNa"
      },
      "source": [
        "# **Homework 2: Hierarchical models & Gibbs sampling**\n",
        "STAT 348, UChicago, Spring 2025\n",
        "\n",
        "----------------\n",
        "**Your name here:**\n",
        "\n",
        "**Hours spent:**\n",
        "\n",
        "(Please let us know how many hours in total you spent on this assignment so we can calibrate for future assignments. Your feedback is always welcome!)\n",
        "\n",
        "----------------\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/aschein/stat_348_2025/blob/main/assignments/hw2/hw2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "---\n",
        "\n",
        "## Instructions\n",
        "\n",
        "This homework focuses on themes in the first four lectures and will also get you working more with Python and PyTorch.\n",
        "\n",
        "Assignment is due **Sunday April 13, 11:59pm** on GradeScope.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hierarchical model for noisy survey data\n",
        "\n",
        "We will consider a model for grouped survey data, where there are $n$ respondents in each of $G$ groups. For each respondent $i \\in \\{1,\\dots, n\\}$ in each group $g \\in\\{1,\\dots,G\\}$, we observe their covariates $\\mathbf{x}_{g,i} \\in \\mathbb{R}^p$ and a scalar summary of their responses $y_{g,i} \\in \\mathbb{R}$.\n",
        "\n",
        "We know that some percentage of each group contains respondents who fill out their survey randomly. (This sometimes happens with paid survey work, like on Mechanical Turk.) We don't know for certain whether any individual respondent answered randomly, so we will use a latent variable model to get denoised estimates of regression coefficients, group-specific means, and other quantities.\n",
        "\n",
        "Consider the following model for noisy grouped survey data. For each respondent $i \\in \\{1,\\dots, n\\}$ in each group $g \\in\\{1,\\dots,G\\}$, their response is conditionally Gaussian:\n",
        "$$\n",
        "\\begin{align*}\n",
        "y_{g,i} &\\sim \\begin{cases}\n",
        "\\mathcal{N}(\\mathbf{x}_{g,i}^\\top \\boldsymbol{\\beta}_g,\\, \\sigma_g^2) &\\textrm{if } z_{g,i} = 1 \\\\[0.5em]\n",
        "\\mathcal{N}(\\mu_0,\\, \\sigma_0^2) &\\textrm{if } z_{g,i} = 0 \\\\\n",
        "\\end{cases}\n",
        "\\end{align*}\n",
        "$$\n",
        "where $z_{g,i} =1$ means that the respondent did not answer randomly and $z_{g,i}=0$ means they did. We don't observe $z_{g,i}$ and treat it as a latent variable:\n",
        "$$\n",
        "\\begin{align*}\n",
        "z_{g,i} &\\sim \\textrm{Bernoulli}(\\rho_g) \\\\\n",
        "\\rho_g &\\sim \\textrm{Beta}(\\alpha_{0,1}, \\alpha_{0,2})\n",
        "\\end{align*}\n",
        "$$\n",
        "where $\\rho_g \\in (0,1)$ is the group-specific rate of \"good\" respondents, for which we assume a conditionally conjugate Beta prior with hyperparameter $\\boldsymbol{\\alpha}_{0}=[\\alpha_{0,1}, \\alpha_{0,2}]$. \n",
        "\n",
        "We further assume the following conditionally conjugate hierarchical prior over the regression parameters for non-random \"good\" responses:\n",
        "$$\n",
        "\\begin{align*}\n",
        "(\\boldsymbol{\\beta}_g, \\sigma_g^2) &\\sim \\textrm{NIX}(\\textbf{m}, L_0, \\nu_0, \\tau_0^2) \\\\\n",
        "\\textbf{m} &\\sim \\mathcal{N}(0, I)\n",
        "\\end{align*}\n",
        "$$\n",
        "We assume that the random responses follow a Gaussian $\\mathcal{N}(\\mu_0,\\, \\sigma_0^2)$ whose hyperparameters we know.\n",
        "\n",
        "The full set of hyperparameters in the model is $\\boldsymbol{\\eta}_0 = \\{\\mu_0, \\sigma_0^2, \\boldsymbol{\\alpha}_0, L_0, \\nu_0, \\tau_0^2\\}$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## **Problem 0:** Draw the graphical model [Visual].\n",
        "\n",
        "Using either sofware (e.g., TikZ, Keynote) or **very neat handwriting**, create a probabilistic graphical model that describes the generative process above. Your PGM should:\n",
        "- Use plate notation to denote repeated sampling.\n",
        "- Use shaded circular nodes to denote observed variables.\n",
        "- Use un-shaded circular nodes to denote latent variables.\n",
        "- Use square or bullet-nodes to denote hyperparameters.\n",
        "\n",
        "Include your image in the space below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "_Your answer here._\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Useful distribution objects\n",
        "\n",
        "For your convenience, we have implemented as `torch.distributions` the `ScaledInvChiSq` and `NIX` distributions below. We will use these distribution objects to implement the generative process in the code below, and you should use them when implementing your Gibbs sampler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-_CGkTvS9dH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.distributions import Gamma, TransformedDistribution, MultivariateNormal\n",
        "from torch.distributions.transforms import PowerTransform\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_context(\"notebook\")\n",
        "\n",
        "class ScaledInvChiSq(TransformedDistribution):\n",
        "    def __init__(self, dof, scale):\n",
        "        \"\"\"\n",
        "        Implementation of the scaled inverse \\chi^2 distribution,\n",
        "\n",
        "        ..math:\n",
        "            \\chi^{-2}(\\nu_0, \\sigma_0^2)\n",
        "\n",
        "        It is equivalent to an inverse gamma distribution, which we implement\n",
        "        as a transformation of a Gamma distribution. Thus, this class inherits\n",
        "        functions like `log_prob` from its parent.\n",
        "\n",
        "        Args:\n",
        "            dof:   degrees of freedom parameter\n",
        "            scale: scale of the $\\chi^{-2}$ distribution.\n",
        "        \"\"\"\n",
        "        base = Gamma(dof / 2, dof * scale / 2)\n",
        "        transforms = [PowerTransform(-1)]\n",
        "        TransformedDistribution.__init__(self, base, transforms)\n",
        "        self.dof = dof\n",
        "        self.scale = scale\n",
        "\n",
        "    def sample(self, sample_shape=torch.Size()):\n",
        "        \"\"\"\n",
        "        Generate samples from the scaled inverse chi-squared distribution.\n",
        "\n",
        "        Args:\n",
        "            sample_shape: Shape of the samples to generate.\n",
        "\n",
        "        Returns:\n",
        "            Samples from the distribution.\n",
        "        \"\"\"\n",
        "        inv_gamma_samples = super().sample(sample_shape)\n",
        "        return inv_gamma_samples\n",
        "\n",
        "class NIX:\n",
        "    def __init__(self, m, L, nu, tausq):\n",
        "        \"\"\"\n",
        "        Implementation of the Normal-Inverse-Chi-Squared (NIX) distribution.\n",
        "\n",
        "        Args:\n",
        "            m: mean of the weights (tensor of shape (p,))\n",
        "            L: precision matrix of the weights (tensor of shape (p, p))\n",
        "            nu: degrees of freedom (scalar tensor)\n",
        "            tausq: scale of the variance parameter (scalar tensor)\n",
        "        \"\"\"\n",
        "        self.m = m\n",
        "        self.L = L\n",
        "        self.nu = nu\n",
        "        self.tausq = tausq\n",
        "\n",
        "    def sample(self, sample_shape=torch.Size()):\n",
        "        \"\"\"\n",
        "        Generate samples from the NIX distribution.\n",
        "\n",
        "        Args:\n",
        "            sample_shape: Shape of the samples to generate.\n",
        "\n",
        "        Returns:\n",
        "            beta_samples: Samples of the weights (tensor of shape (*sample_shape, p))\n",
        "            sigmasq_samples: Samples of the variance (tensor of shape (*sample_shape,))\n",
        "        \"\"\"\n",
        "        sigmasq_samples = ScaledInvChiSq(self.nu, self.tausq).sample(sample_shape)\n",
        "        L_inv = torch.inverse(self.L)\n",
        "        beta_samples = MultivariateNormal(self.m, sigmasq_samples[..., None, None] * L_inv).sample()\n",
        "        return beta_samples, sigmasq_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The \"forward\" sampler\n",
        "\n",
        "For your convenience, we have also implemented a function to sample from prior (i.e., the \"forward\" sampler in `sample_state_forward`). This will yield a dictionary of latent variables that we call the model's `state`.\n",
        "\n",
        "We have also implemented a function to sample from the likelihood in `sample_Y`, which takes in a model `state` and returns a sample from the likelihood. This function relies on another function called `get_likelihood` which returns a `torch.distributions.Normal` object; this function may be useful to you in what you implement, so we recommend you study the code.\n",
        "\n",
        "The code here also contains examples of how to sample from PyTorch distribution objects without using for-loops (which are very slow in Python), along with examples of indexing, `torch.einsum`, and various other snippets of code that you may find useful.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.distributions import Normal, Beta, Bernoulli\n",
        "\n",
        "def sample_state_forward(X, hypers):\n",
        "    \"\"\"\n",
        "    Samples the state variables for the forward sampler.\n",
        "\n",
        "    Args:\n",
        "        X (torch.Tensor): covariates (groups x respondents x features)\n",
        "        hypers (dict): dictionary containing the hyperparameters\n",
        "            - \"L_0\": torch.Tensor, prior precision matrix of shape (p, p)\n",
        "            - \"nu_0\": float, prior degrees of freedom\n",
        "            - \"tausq_0\": float, prior scale of variance\n",
        "            - \"alpha\": tuple of floats, parameters of the Beta distribution\n",
        "\n",
        "    Returns:\n",
        "        dict\n",
        "            A dictionary containing the sampled state variables:\n",
        "            - \"m_P\": torch.Tensor, sampled prior mean of shape (p,)\n",
        "            - \"beta_GP\": torch.Tensor, sampled regression coefficients of shape (G, p)\n",
        "            - \"sigmasq_G\": torch.Tensor, sampled variances of shape (G,)\n",
        "            - \"rho_G\": torch.Tensor, sampled probabilities of shape (G,)\n",
        "            - \"Z_GN\": torch.Tensor, sampled binary indicators of shape (G, n)\n",
        "    \"\"\"\n",
        "    G, n, p = X.shape\n",
        "    m_P = Normal(0, 1).sample((p,))\n",
        "    beta_GP, sigmasq_G = NIX(m=m_P,\n",
        "                             L=hypers[\"L_0\"], \n",
        "                             nu=hypers[\"nu_0\"], \n",
        "                             tausq=hypers[\"tausq_0\"]).sample(sample_shape=(G,))\n",
        "    \n",
        "    alpha1, alpha2 = hypers[\"alpha\"]\n",
        "    rho_G = Beta(alpha1, alpha2).sample((G,))\n",
        "    Z_GN = Bernoulli(rho_G).sample((n,)).T\n",
        "\n",
        "    state = {\n",
        "        \"m_P\": m_P,\n",
        "        \"beta_GP\": beta_GP,\n",
        "        \"sigmasq_G\": sigmasq_G,\n",
        "        \"rho_G\": rho_G,\n",
        "        \"Z_GN\": Z_GN\n",
        "    }\n",
        "    return state\n",
        "\n",
        "\n",
        "def get_likelihood(X, state, hypers):\n",
        "    \"\"\"\n",
        "        Computes the likelihood of the observed data given the current state and hyperparameters.\n",
        "\n",
        "        Args:\n",
        "            X (torch.Tensor): covariates (groups x respondents x features)\n",
        "            state (dict): dictionary containing the current state variables\n",
        "            hypers (dict): dictionary containing the hyperparameters\n",
        "\n",
        "        Returns:\n",
        "            torch.distributions.Normal: A Normal distribution object representing the likelihood\n",
        "                of the observed data given the current state and hyperparameters.\n",
        "    \"\"\"\n",
        "    G, n, p = X.shape\n",
        "    mu_0, sigmasq_0 = hypers[\"mu_0\"], hypers[\"sigmasq_0\"]\n",
        "    beta_GP, sigmasq_G, Z_GN = [state[key] for key in [\"beta_GP\", \"sigmasq_G\", \"Z_GN\"]]\n",
        "\n",
        "    mu_GN = torch.einsum(\"gj,gij->gi\", beta_GP, X)\n",
        "    mu_GN[Z_GN == 0] = mu_0\n",
        "\n",
        "    sigmasq_GN = sigmasq_G.repeat(n, 1).T\n",
        "    sigmasq_GN[Z_GN == 0] = sigmasq_0\n",
        "    return Normal(mu_GN, torch.sqrt(sigmasq_GN))\n",
        "\n",
        "\n",
        "def sample_Y(X, state, hypers):\n",
        "    \"\"\"\n",
        "        Generates synthetic data based on the current state and hyperparameters.\n",
        "\n",
        "        Args:\n",
        "            X (torch.Tensor): covariates (groups x respondents x features)\n",
        "            state (dict): dictionary containing the current state variables\n",
        "            hypers (dict): dictionary containing the hyperparameters\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Y sampled from the likelihood distribution (groups x respondents)\n",
        "    \"\"\"\n",
        "    return get_likelihood(X, state, hypers).sample()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Problem 1:** Derive the complete conditionals [Math]\n",
        "\n",
        "**1a):** Derive the complete conditional distribution $p(z_{g,i} \\mid -)$. Here the $-$ notation means \"everything\", which includes $\\textbf{X}$, $\\textbf{Y}$, all latent variables other than $z_{g,i}$, and all hyperparameters.\n",
        "\n",
        "---\n",
        "\n",
        "$$p(z_{g,i} \\mid -) = \\textrm{Your answer here.}$$ \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**1b):** Derive the complete conditional of $\\rho_{g}$.\n",
        "\n",
        "---\n",
        "\n",
        "$$p(\\rho_{g} \\mid -) = \\textrm{Your answer here.}$$ \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**1c):** Derive the complete conditional of $(\\boldsymbol{\\beta}_g, \\sigma_g^2)$.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "$$p(\\boldsymbol{\\beta}_g, \\sigma_g^2 \\mid -) = \\textrm{Your answer here.}$$ \n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**1d):** Derive the complete conditional of $\\textbf{m}$.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "$$p(\\textbf{m} \\mid -) = \\textrm{Your answer here.}$$ \n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Problem 2:** Implement the complete conditionals [Code]\n",
        "\n",
        "**2a):** Implement the complete conditional of $z_{g,i}$.\n",
        "\n",
        "For this, you should make sure your implementation is numerically stable by computing things in log-space using the **logsumexp trick**. You can read about the math of the logsumexp trick [here]((https://gregorygundersen.com/blog/2020/02/09/log-sum-exp/)). Your implementation should involve `torch.logsumexp` which you can read about [here](https://pytorch.org/docs/stable/generated/torch.logsumexp.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def update_Z_GN(Y, X, state, hypers):\n",
        "    \"\"\"\n",
        "    Update the binary latent variable Z_GN based on the current state, data, \n",
        "    and hyperparameters. This function should compute the log-probabilities for \n",
        "    Z_GN being 0 vs 1, normalizes them in log-space to log-probabilities, and then \n",
        "    samples new values for Z_GN from the resulting Bernoulli distribution.\n",
        "\n",
        "    Args:\n",
        "        Y (torch.Tensor): Observed responses (groups x respondents).\n",
        "        X (torch.Tensor): Covariates (groups x respondents x features).\n",
        "        state (dict): Current state of the model containing latent variables.\n",
        "        hypers (dict): Dictionary of hyperparameters.\n",
        "\n",
        "        NOTE: By default, we pass (Y, X, state, hypers) to all complete conditionals,\n",
        "        however certain complete conditionals may not require some of these inputs.\n",
        "\n",
        "    Returns:\n",
        "        None: Updates the 'Z_GN' key in the state dictionary in-place.\n",
        "    \n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    \n",
        "    # log_p_GN = ...\n",
        "\n",
        "    p_GN = torch.exp(log_p_GN)\n",
        "    assert torch.isfinite(p_GN).all()\n",
        "    state['Z_GN'] = Bernoulli(p_GN).sample()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**2b):** Implement the complete conditional of $\\rho_{g}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def update_rho_G(Y, X, state, hypers):\n",
        "    \"\"\" Update the probabilities rho_G based on the current state, data, \n",
        "    and hyperparameters. \n",
        "\n",
        "    Args:\n",
        "        Y (torch.Tensor): Observed responses (groups x respondents).\n",
        "        X (torch.Tensor): Covariates (groups x respondents x features).\n",
        "        state (dict): Current state of the model containing latent variables.\n",
        "        hypers (dict): Dictionary of hyperparameters containing:\n",
        "\n",
        "    Returns:\n",
        "        None: Updates the 'rho_G' key in the state dictionary in-place.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    # rho_G = ...\n",
        "\n",
        "    state['rho_G'] = rho_G"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**2c):** Implement the complete conditional of $(\\boldsymbol{\\beta}_g, \\sigma_g^2)$.\n",
        "\n",
        "**Hint:** you have derivations and code from HW1 that you could re-use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def update_regression_params(Y, X, state, hypers):\n",
        "    \"\"\" Update the regression parameters based on the current state, data, \n",
        "    and hyperparameters. \n",
        "\n",
        "    Args:\n",
        "        Y (torch.Tensor): Observed responses (groups x respondents).\n",
        "        X (torch.Tensor): Covariates (groups x respondents x features).\n",
        "        state (dict): Current state of the model containing latent variables.\n",
        "        hypers (dict): Dictionary of hyperparameters containing:\n",
        "\n",
        "    Returns:\n",
        "        None: Updates the 'beta_GP' and `sigmasq_G' keys in the state dictionary in-place.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE \n",
        "    # state['beta_GP'] = ...\n",
        "    # state['sigmasq_G'] = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**2d):** Implement the complete conditional of $\\textbf{m}$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def update_m_P(Y, X, state, hypers):\n",
        "    \"\"\" Update the mean of regression coefficients m_P based on the current state, data, \n",
        "    and hyperparameters. \n",
        "\n",
        "    Args:\n",
        "        Y (torch.Tensor): Observed responses (groups x respondents).\n",
        "        X (torch.Tensor): Covariates (groups x respondents x features).\n",
        "        state (dict): Current state of the model containing latent variables.\n",
        "        hypers (dict): Dictionary of hyperparameters containing:\n",
        "\n",
        "    Returns:\n",
        "        None: Updates the 'm_P' key in the state dictionary in-place.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE \n",
        "    # state['m_P'] = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gibbs sampler\n",
        "\n",
        "For your convenience, we have implemented the function `gibbs` which relies on the complete conditionals you implemented in problem 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def get_gibbs_transition(Y, X, hypers):\n",
        "    \"\"\"Returns a function that performs a single Gibbs transition\n",
        "    \n",
        "    Args:\n",
        "        Y (torch tensor): responses (groups x respondents)\n",
        "        X (torch tensor): covariates (groups x respondents x features)\n",
        "        hypers (dict): dictionary containing the hyperparameters\n",
        "    \n",
        "    Returns:\n",
        "        function: function that performs a single Gibbs transition\n",
        "    \"\"\"\n",
        "    def gibbs_transition(state):\n",
        "        update_Z_GN(Y, X, state, hypers)\n",
        "        update_rho_G(Y, X, state, hypers)\n",
        "        update_regression_params(Y, X, state, hypers)\n",
        "        update_m_P(Y, X, state, hypers)\n",
        "        return state\n",
        "\n",
        "    return gibbs_transition\n",
        "\n",
        "\n",
        "def gibbs(Y, X, hypers, n_samples=250, n_burnin=100, n_thin=5):\n",
        "    \"\"\"Gibbs sampler\n",
        "\n",
        "    Args:\n",
        "        Y (torch tensor): responses (groups x respondents)\n",
        "        X (torch tensor): covariates (groups x respondents x features)\n",
        "        hypers (dict): dictionary containing the hyperparameters\n",
        "        n_samples (int, optional): number of posterior samples to collect. \n",
        "        n_burnin (int, optional): number of burn-in samples.\n",
        "        n_thin (int, optional): thinning parameter. Only collect every n_thin samples.\n",
        "    \n",
        "    Returns:\n",
        "        posterior_samples (list): list of posterior samples, each sample is a state dictionary\n",
        "    \"\"\"\n",
        "    # initialize the state from the prior\n",
        "    state = sample_state_forward(X, hypers)\n",
        "    \n",
        "    # get the transition operator\n",
        "    gibbs_transition = get_gibbs_transition(Y, X, hypers)\n",
        "\n",
        "    # burn-in samples\n",
        "    for _ in tqdm(range(n_burnin)):\n",
        "        state = gibbs_transition(state)\n",
        "    \n",
        "    posterior_samples = []\n",
        "    for m in tqdm(range(n_samples * n_thin)):\n",
        "        state = gibbs_transition(state)\n",
        "\n",
        "        # only collect every n_thin samples\n",
        "        if m % n_thin == 0:\n",
        "            # make sure to deepcopy so the code does not modify the collected states\n",
        "            posterior_samples.append(deepcopy(state)) \n",
        "    \n",
        "    return posterior_samples  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Problem 3:** Geweke testing [Code, results]\n",
        "\n",
        "In this problem you will implement and run a Geweke test to ensure your Gibbs sampler is correctly derived and implemented.\n",
        "\n",
        "See the lecture notes, along with [Grosse & Duvenaud (2014)](https://arxiv.org/pdf/1412.5218.pdf) and [Geweke (2004)](https://www.jstor.org/stable/27590449) for details on Geweke testing.\n",
        "\n",
        "In general, a Geweke test compares two sets of samples which should both be iid from the joint distribution $p(\\textbf{Y}, \\textbf{Z})$ of data $\\textbf{Y}$ and latent variables $\\textbf{Z}$ (note here $\\textbf{Z}$ means **all** latent variables in a model). The first set of samples are the **forward samples** ($\\textbf{Y}_m^f$, $\\textbf{Z}_m^f)_{m=1}^M$ which are drawn iid:\n",
        "$$\\begin{align*}\n",
        "\\textbf{Z}_m^f &\\sim p(\\textbf{Z}) & \\textrm{prior} \\\\\n",
        "\\textbf{Y}_m^f &\\sim p(\\textbf{Y} \\mid \\textbf{Z}_m^f) &\\textrm{likelihood}\n",
        "\\end{align*}\n",
        "$$\n",
        "The second set of samples are the **backward samples** ($\\textbf{Y}_m^b$, $\\textbf{Z}_m^b)_{m=1}^M$ which are drawn using Gibbs sampling:\n",
        "$$\\begin{align*}\n",
        "\\textbf{Z}_m^b &\\sim \\pi(\\textbf{Z} \\mid \\textbf{Z}_{m-1}^b, \\textbf{Y}_{m-1}^f)  & \\textrm{Gibbs transition kernel}\\\\\n",
        "\\textbf{Y}_m^b &\\sim p(\\textbf{Y} \\mid \\textbf{Z}_m^b) & \\textrm{likelihood}\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "**3a):** Finish implementing `geweke_test` below by implementing the backward sampler. The backward sampler should:\n",
        "- First, initialize all latent variables and data with a draw from the prior / likelihood (i.e., using a forward sample).\n",
        "\n",
        "- Then, it should run 10,000 iterations of burn-in, and then another 50,000 iterations, saving every 5th sample. The output should be 10,000 samples, each of which is a dictionary containing latent variables **and data**.\n",
        "\n",
        "- Make sure that your backward sampler is indeed generating samples from the joint distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def geweke_test(X, hypers, n_samples=10000, n_burnin=10000, n_thin=5):\n",
        "    \"\"\"Geweke test\n",
        "    \n",
        "    Args:\n",
        "        X (torch tensor): covariates (groups x respondents x features)\n",
        "        hypers (dict): dictionary containing the hyperparameters\n",
        "        n_samples (int, optional): number of forward and backward samples to collect.\n",
        "        n_burnin (int, optional): number of burn-in samples.\n",
        "        n_thin (int, optional): thinning parameter. Only collect every n_thin samples.\n",
        "    \n",
        "    Returns:\n",
        "        forward_samples (list): list of forward samples, each sample is a state dictionary\n",
        "        backward_samples (list): list of backward samples, each sample is a state dictionary\n",
        "    \n",
        "    References:\n",
        "        [1] Grosse & Duvenaud (2014) \"Testing MCMC Code\": https://arxiv.org/pdf/1412.5218.pdf\n",
        "        [2] Geweke (2004) \"Getting it right...\": https://www.jstor.org/stable/27590449\n",
        "    \"\"\"\n",
        "\n",
        "    # sample forward from the prior and likelihood\n",
        "    forward_samples = []\n",
        "    for _ in tqdm(range(n_samples)):\n",
        "        state = sample_state_forward(X, hypers)\n",
        "        state['Y'] = sample_Y(X, state, hypers)\n",
        "        forward_samples.append(deepcopy(state))  \n",
        "    \n",
        "    \n",
        "    backward_samples = []\n",
        "    # YOUR CODE HERE\n",
        "    \n",
        "    return forward_samples, backward_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3b):** Now run the cell below to Geweke test your code. The output should be two PP-plots that compare the means $\\rho_g$ and $\\mathbf{m}$ between the forward and backward sample. The PP-plots should be **straight along the diagonal**; if they are not straight, there is a bug in the derivation or code (or both) of your Gibbs sampler. For reference, running this took our implementation 3 minutes; if it is much slower for you, you should investigate the bottlenecks in your code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pp_plot import pp_plot\n",
        "\n",
        "# You can/should use small G, p, n for the purposes of testing to speed up the code\n",
        "# Theoretically, your code should pass the Geweke test for any setting of hyperparams.\n",
        "G = 3\n",
        "p = 2\n",
        "n = 10\n",
        "\n",
        "X = Normal(0, 0.1).sample((G, n, p))\n",
        "X[:, :, 0] = 1.0\n",
        "\n",
        "hypers = {\"m_0\": torch.zeros(p),\n",
        "          \"L_0\": torch.eye(p) * 1,\n",
        "          \"nu_0\": 1.0,\n",
        "          \"tausq_0\": 0.1,\n",
        "          \"alpha\": torch.Tensor([5., 1.]),\n",
        "          \"mu_0\": -1.0,\n",
        "          \"sigmasq_0\": 2.0}\n",
        "\n",
        "forward_samples, backward_samples = geweke_test(X=X, \n",
        "                                                hypers=hypers, \n",
        "                                                n_samples=10000, \n",
        "                                                n_burnin=10000, \n",
        "                                                n_thin=5)\n",
        "\n",
        "# Compare the arithmetic mean of the rho_G parameters across samples\n",
        "arr1 = [state['rho_G'].mean() for state in forward_samples]\n",
        "arr2 = [state['rho_G'].mean() for state in backward_samples]\n",
        "pp_plot(arr1, arr2, 'Geweke test for E[rho_g]')\n",
        "\n",
        "# Compare the arithmetic mean of the m_P parameters across samples\n",
        "arr1 = [state['m_P'].mean() for state in forward_samples]\n",
        "arr2 = [state['m_P'].mean() for state in backward_samples]\n",
        "pp_plot(arr1, arr2, 'Geweke test for E[m_P]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Problem 4:** Gibbs sampling on the real data [Code, plotting, results]\n",
        "\n",
        "Now load in the \"real\" training data and run Gibbs sampling for 1000 burn-in, and then another 5000, collecting every 5th sample. This should return 1000 posterior samples. For reference, our implementation runs in 45 seconds. If yours is taking much longer, you should look into your code's bottlenecks.\n",
        "\n",
        "After running Gibbs sampling, use your posterior samples to visualize the posterior distribution of $\\textbf{m}$. There are $p$ dimensions of $\\textbf{m}$, so you should create a plot that visualizes posterior uncertainty over all $p$ dimensions (e.g., $p$ histograms)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Y_train, X_train = torch.load(\"data_train.pt\")\n",
        "G, n, p = X.shape\n",
        "\n",
        "hypers = {\"L_0\": torch.eye(p) * 1,\n",
        "          \"nu_0\": 1.0,\n",
        "          \"tausq_0\": 0.1,\n",
        "          \"alpha\": torch.Tensor([5., 1.]),\n",
        "          \"mu_0\": -5.0,\n",
        "          \"sigmasq_0\": 2.0}\n",
        "\n",
        "samples = gibbs(Y_train, X_train, hypers, n_samples=1000, n_burnin=1000, n_thin=5)\n",
        "\n",
        "# YOUR CODE HERE (this should visualize posterior uncertainty over m_P).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Problem 5**: Denoised group means [Code]\n",
        "In this problem you are going to visualize the posterior uncertainty about the group-specific mean of non-anomalous responses---i.e.:\n",
        "$$\\bar{y}^\\star_g \\triangleq \\frac{\\sum_{i=1}^{n_g} y_{g,i} \\, z_{g,i}}{\\sum_{i=1}^{n_g} z_{g,i}} $$\n",
        "\n",
        "If we knew $z_{g,i}$, we could compute this. However, our uncertainty about $z_{g,i}$ induces uncertainty about $\\bar{y}^\\star_g$---i.e., we are interested in the following posterior:\n",
        "\n",
        "$$p(\\bar{y}^\\star_g \\mid \\mathbf{Y}, \\mathbf{X})$$\n",
        "\n",
        "For each group $g$, use your posterior samples to approximate and visualize uncertainty about $\\bar{y}^\\star_g$ under the posterior distribution. More specifically:\n",
        "- Plot $G$ box-plots, each of which displays the **interquartile range** of $\\bar{y}^\\star_g$ under the posterior distribution.\n",
        "- Each box-plot should also display the **posterior mean** of $\\bar{y}^\\star_g$ as a **red star**.\n",
        "- The box-plots should all be in the same plot, with the group index $g$ on the x-axis, and a shared y-axis.\n",
        "- For comparison, also plot the simple mean $\\bar{y}_g = \\tfrac{1}{n}\\sum_{i=1}^n y_{g,i}$ as a **yellow diamond**.\n",
        "- Ensure that all your axes are labeled and you have an informative legend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "## YOUR CODE HERE (this should display the described plot when run)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Problem 6**: Posterior predictive of $z_{g,i}$ [Math, code]\n",
        "In this problem you are going to derive and implement a Monte Carlo approximation for the posterior predictive probability that a new unseen data point in group $g$ is not anomalous---i.e.:\n",
        "$$p(z^{\\textrm{test}}_{g, i} = 1\\mid \\mathbf{x}^{\\textrm{test}}_{g, i}, \\mathbf{Y}, \\mathbf{X})$$\n",
        "\n",
        "**6a):** First, provide the mathematical form of your Monte Carlo approximation, which should involve posterior samples of latent variables (e.g., using $\\rho^m_{g}$ to denote the $m^{\\textrm{th}}$ posterior sample of variable $\\rho_{g}$).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "$$p(z^{\\textrm{test}}_{g, i} = 1\\mid \\mathbf{x}^{\\textrm{test}}_{g, i}, \\mathbf{Y}, \\mathbf{X}) \\approx \\textrm{Your answer here.}$$\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**6b):** Now implement your Monte Carlo estimator in the function `posterior_predictive_z`, and run the code so it prints out some test values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Y_test, X_test = torch.load(\"data_test.pt\")\n",
        "\n",
        "def posterior_predictive_z_g(x, g, samples, hypers):\n",
        "    \"\"\"\n",
        "    Compute the posterior predictive probability that a new unseen data point \n",
        "    in group g is not anomalous, i.e., p(z^{test}_{g, i} = 1 | x^{test}_{g, i}, Y, X).\n",
        "\n",
        "    Args:\n",
        "        x (torch.Tensor): Covariates for the new unseen data point.\n",
        "        g (int): Group index for the new unseen data point.\n",
        "        samples (list): List of posterior samples, where each sample is a state dictionary.\n",
        "        hypers (dict): Dictionary of hyperparameters.\n",
        "\n",
        "    NOTE: By default, we pass (x, g, samples, hypers), however this \n",
        "    may not require some of these inputs.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor or float: Posterior predictive probability.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "# Print the posterior predictive for the first test data point in each group.\n",
        "print([posterior_predictive_z_g(X_test[g, 0], g, samples, hypers) for g in range(G)])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Problem 7**: Scaled pointwise predictive density [Math, code]\n",
        "In this problem you are going to compute a Monte Carlo approximation to the **scaled pointwise predictive density (SPPD)** of the test data, defined as:\n",
        "\n",
        "$$\\textrm{SPPD} = \\exp \\left(\\tfrac{1}{G \\, n_{\\textrm{test}}} \\sum_{g=1}^G \\sum_{i=1}^{n_{\\textrm{test}}} \\log p(y^{\\textrm{test}}_{g,i} \\mid \\textbf{x}_{g,i}^{\\textrm{test}}, \\textbf{Y}^{\\textrm{train}}, \\textbf{X}^{\\textrm{train}})\\right)$$\n",
        "\n",
        "where the term $\\log p(y^{\\textrm{test}}_{g,i} \\mid \\textbf{x}_{g,i}^{\\textrm{test}}, \\textbf{Y}^{\\textrm{train}}, \\textbf{X}^{\\textrm{train}})$ is the (natural) log of the **posterior predictive density** of heldout test data point $(y^{\\textrm{test}}_{g,i}, \\textbf{x}_{g,i}^{\\textrm{test}})$. \n",
        "\n",
        "SPPD is a measure of heldout predictive performance, which takes the geometric mean of the posterior predictive densities on the heldout test points. In this case, the same number of points $n_{\\textrm{test}}$ have been heldout of each group $g$, making the total number of test points equal to $Gn_{\\textrm{test}}$\n",
        "\n",
        "In this problem, you will derive and implement a Monte Carlo approximation of SPPD which uses the posterior samples obtained during Gibbs sampling. \n",
        "\n",
        "**7a):** First, provide the mathematical form of your Monte Carlo approximation, which should involve posterior samples of latent variables (e.g., using $z^m_{g, i}$ to denote the $m^{\\textrm{th}}$ posterior sample of variable $z_{g, i}$).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "$$\\textrm{SPPD} \\approx \\textrm{Your answer here.}$$\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**7b):** Now implement your Monte Carlo estimator. Your implementation should be numerically stable, and should compute everything in log-space, **using again the logsumexp trick**. You should **only** move out of log-space at the very end. After implementing `scaled_ppd`, run the code to print out the value of SPPD on the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def scaled_ppd(Y, X, samples, hypers):\n",
        "    \"\"\"Computes the scaled pointwise predictive density (PPD) for the test data.\n",
        "\n",
        "    Args:\n",
        "        Y (torch.Tensor): Observed responses for the test data.\n",
        "        X (torch.Tensor): Covariates for the test data.\n",
        "        samples (list): List of posterior samples, where each sample is a state dictionary.\n",
        "        hypers (dict): Dictionary of hyperparameters.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor or float: The scaled pointwise predictive density.\n",
        "    \"\"\"\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "print(scaled_ppd(Y_test, X_test, samples, hypers))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hM9vMLLP9J1n"
      },
      "source": [
        "## Submission Instructions\n",
        "\n",
        "\n",
        "**Formatting:** check that your code does not exceed 80 characters in line width. You can set _Tools &rarr; Settings &rarr; Editor &rarr; Vertical ruler column_ to 80 to see when you've exceeded the limit. \n",
        "\n",
        "Download your notebook in .ipynb format and use the following commands to convert it to PDF.  Then run the following command to convert to a PDF:\n",
        "```\n",
        "jupyter nbconvert --to pdf <yourlastname>_hw1.ipynb\n",
        "```\n",
        "(Note that for the above code to work, you need to rename your file `<yourlastname>_hw1.ipynb`)\n",
        "\n",
        "Possible causes for errors:\n",
        "  * the \"Open in colab\" button. Just delete the code that creates this button (go to the top cell and delete it)\n",
        "  * Latex errors: many latex errors aren't visible in the notebook. Try binary search: comment out half of the latex at a time, until you find the bugs\n",
        "\n",
        "Getting this HW into PDF form isn't meant to be a burden. One quick and easy approach is to open it as a Jupyter notebook, print, save to pdf. Just make sure your latex math answers aren't cut off so we can grade them.\n",
        "\n",
        "Please post on Ed or come to OH if there are any other problems submitting the HW.\n",
        "\n",
        "**Installing nbconvert:**\n",
        "\n",
        "If you're using Anaconda for package management, \n",
        "```\n",
        "conda install -c anaconda nbconvert\n",
        "```\n",
        "\n",
        "**Upload** your .pdf file to Gradescope. Please tag your questions!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "b6k2BC4ZeFpS"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
